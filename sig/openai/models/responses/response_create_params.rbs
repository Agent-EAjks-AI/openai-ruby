module OpenAI
  module Models
    module Responses
      type response_create_params =
        {
          input: OpenAI::Models::Responses::ResponseCreateParams::input,
          model: OpenAI::Models::responses_model,
          background: bool?,
          include: ::Array[OpenAI::Models::Responses::response_includable]?,
          instructions: String?,
          max_output_tokens: Integer?,
          metadata: OpenAI::Models::metadata?,
          parallel_tool_calls: bool?,
          previous_response_id: String?,
          prompt: OpenAI::Responses::ResponsePrompt?,
          reasoning: OpenAI::Reasoning?,
          service_tier: OpenAI::Models::Responses::ResponseCreateParams::service_tier?,
          store: bool?,
          temperature: Float?,
          text: OpenAI::Responses::ResponseTextConfig,
          tool_choice: OpenAI::Models::Responses::ResponseCreateParams::tool_choice,
          tools: ::Array[OpenAI::Models::Responses::tool],
          top_p: Float?,
          truncation: OpenAI::Models::Responses::ResponseCreateParams::truncation?,
          user: String
        }
        & OpenAI::Internal::Type::request_parameters

      class ResponseCreateParams < OpenAI::Internal::Type::BaseModel
        extend OpenAI::Internal::Type::RequestParameters::Converter
        include OpenAI::Internal::Type::RequestParameters

        attr_accessor input: OpenAI::Models::Responses::ResponseCreateParams::input

        attr_accessor model: OpenAI::Models::responses_model

        attr_accessor background: bool?

        attr_accessor include: ::Array[OpenAI::Models::Responses::response_includable]?

        attr_accessor instructions: String?

        attr_accessor max_output_tokens: Integer?

        attr_accessor metadata: OpenAI::Models::metadata?

        attr_accessor parallel_tool_calls: bool?

        attr_accessor previous_response_id: String?

        attr_accessor prompt: OpenAI::Responses::ResponsePrompt?

        attr_accessor reasoning: OpenAI::Reasoning?

        attr_accessor service_tier: OpenAI::Models::Responses::ResponseCreateParams::service_tier?

        attr_accessor store: bool?

        attr_accessor temperature: Float?

        attr_reader text: OpenAI::Responses::ResponseTextConfig?

        def text=: (
          OpenAI::Responses::ResponseTextConfig
        ) -> OpenAI::Responses::ResponseTextConfig

        attr_reader tool_choice: OpenAI::Models::Responses::ResponseCreateParams::tool_choice?

        def tool_choice=: (
          OpenAI::Models::Responses::ResponseCreateParams::tool_choice
        ) -> OpenAI::Models::Responses::ResponseCreateParams::tool_choice

        attr_reader tools: ::Array[OpenAI::Models::Responses::tool]?

        def tools=: (
          ::Array[OpenAI::Models::Responses::tool]
        ) -> ::Array[OpenAI::Models::Responses::tool]

        attr_accessor top_p: Float?

        attr_accessor truncation: OpenAI::Models::Responses::ResponseCreateParams::truncation?

        attr_reader user: String?

        def user=: (String) -> String

        def initialize: (
          input: OpenAI::Models::Responses::ResponseCreateParams::input,
          model: OpenAI::Models::responses_model,
          ?background: bool?,
          ?include: ::Array[OpenAI::Models::Responses::response_includable]?,
          ?instructions: String?,
          ?max_output_tokens: Integer?,
          ?metadata: OpenAI::Models::metadata?,
          ?parallel_tool_calls: bool?,
          ?previous_response_id: String?,
          ?prompt: OpenAI::Responses::ResponsePrompt?,
          ?reasoning: OpenAI::Reasoning?,
          ?service_tier: OpenAI::Models::Responses::ResponseCreateParams::service_tier?,
          ?store: bool?,
          ?temperature: Float?,
          ?text: OpenAI::Responses::ResponseTextConfig,
          ?tool_choice: OpenAI::Models::Responses::ResponseCreateParams::tool_choice,
          ?tools: ::Array[OpenAI::Models::Responses::tool],
          ?top_p: Float?,
          ?truncation: OpenAI::Models::Responses::ResponseCreateParams::truncation?,
          ?user: String,
          ?request_options: OpenAI::request_opts
        ) -> void

        def to_hash: -> {
          input: OpenAI::Models::Responses::ResponseCreateParams::input,
          model: OpenAI::Models::responses_model,
          background: bool?,
          include: ::Array[OpenAI::Models::Responses::response_includable]?,
          instructions: String?,
          max_output_tokens: Integer?,
          metadata: OpenAI::Models::metadata?,
          parallel_tool_calls: bool?,
          previous_response_id: String?,
          prompt: OpenAI::Responses::ResponsePrompt?,
          reasoning: OpenAI::Reasoning?,
          service_tier: OpenAI::Models::Responses::ResponseCreateParams::service_tier?,
          store: bool?,
          temperature: Float?,
          text: OpenAI::Responses::ResponseTextConfig,
          tool_choice: OpenAI::Models::Responses::ResponseCreateParams::tool_choice,
          tools: ::Array[OpenAI::Models::Responses::tool],
          top_p: Float?,
          truncation: OpenAI::Models::Responses::ResponseCreateParams::truncation?,
          user: String,
          request_options: OpenAI::RequestOptions
        }

        type input = String | OpenAI::Models::Responses::response_input

        module Input
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Responses::ResponseCreateParams::input]
        end

        type service_tier = :auto | :default | :flex | :scale

        module ServiceTier
          extend OpenAI::Internal::Type::Enum

          AUTO: :auto
          DEFAULT: :default
          FLEX: :flex
          SCALE: :scale

          def self?.values: -> ::Array[OpenAI::Models::Responses::ResponseCreateParams::service_tier]
        end

        type tool_choice =
          OpenAI::Models::Responses::tool_choice_options
          | OpenAI::Responses::ToolChoiceTypes
          | OpenAI::Responses::ToolChoiceFunction

        module ToolChoice
          extend OpenAI::Internal::Type::Union

          def self?.variants: -> ::Array[OpenAI::Models::Responses::ResponseCreateParams::tool_choice]
        end

        type truncation = :auto | :disabled

        module Truncation
          extend OpenAI::Internal::Type::Enum

          AUTO: :auto
          DISABLED: :disabled

          def self?.values: -> ::Array[OpenAI::Models::Responses::ResponseCreateParams::truncation]
        end
      end
    end
  end
end
