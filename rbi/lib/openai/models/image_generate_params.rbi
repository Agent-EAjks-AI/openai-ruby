# typed: strong

module OpenAI
  module Models
    class ImageGenerateParams < OpenAI::Internal::Type::BaseModel
      extend OpenAI::Internal::Type::RequestParameters::Converter
      include OpenAI::Internal::Type::RequestParameters

      # A text description of the desired image(s). The maximum length is 32000
      # characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters
      # for `dall-e-3`.
      sig { returns(String) }
      attr_accessor :prompt

      # Allows to set transparency for the background of the generated image(s). This
      # parameter is only supported for `gpt-image-1`. Must be one of `transparent`,
      # `opaque` or `auto` (default value). When `auto` is used, the model will
      # automatically determine the best background for the image.
      #
      # If `transparent`, the output format needs to support transparency, so it should
      # be set to either `png` (default value) or `webp`.
      sig { returns(T.nilable(OpenAI::Models::ImageGenerateParams::Background::OrSymbol)) }
      attr_accessor :background

      # The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or
      # `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to
      # `gpt-image-1` is used.
      sig { returns(T.nilable(T.any(String, OpenAI::Models::ImageModel::OrSymbol))) }
      attr_accessor :model

      # Control the content-moderation level for images generated by `gpt-image-1`. Must
      # be either `low` for less restrictive filtering or `auto` (default value).
      sig { returns(T.nilable(OpenAI::Models::ImageGenerateParams::Moderation::OrSymbol)) }
      attr_accessor :moderation

      # The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only
      # `n=1` is supported.
      sig { returns(T.nilable(Integer)) }
      attr_accessor :n

      # The compression level (0-100%) for the generated images. This parameter is only
      # supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and
      # defaults to 100.
      sig { returns(T.nilable(Integer)) }
      attr_accessor :output_compression

      # The format in which the generated images are returned. This parameter is only
      # supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.
      sig { returns(T.nilable(OpenAI::Models::ImageGenerateParams::OutputFormat::OrSymbol)) }
      attr_accessor :output_format

      # The quality of the image that will be generated.
      #
      # - `auto` (default value) will automatically select the best quality for the
      #   given model.
      # - `high`, `medium` and `low` are supported for `gpt-image-1`.
      # - `hd` and `standard` are supported for `dall-e-3`.
      # - `standard` is the only option for `dall-e-2`.
      sig { returns(T.nilable(OpenAI::Models::ImageGenerateParams::Quality::OrSymbol)) }
      attr_accessor :quality

      # The format in which generated images with `dall-e-2` and `dall-e-3` are
      # returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes
      # after the image has been generated. This parameter isn't supported for
      # `gpt-image-1` which will always return base64-encoded images.
      sig { returns(T.nilable(OpenAI::Models::ImageGenerateParams::ResponseFormat::OrSymbol)) }
      attr_accessor :response_format

      # The size of the generated images. Must be one of `1024x1024`, `1536x1024`
      # (landscape), `1024x1536` (portrait), or `auto` (default value) for
      # `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and
      # one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.
      sig { returns(T.nilable(OpenAI::Models::ImageGenerateParams::Size::OrSymbol)) }
      attr_accessor :size

      # The style of the generated images. This parameter is only supported for
      # `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean
      # towards generating hyper-real and dramatic images. Natural causes the model to
      # produce more natural, less hyper-real looking images.
      sig { returns(T.nilable(OpenAI::Models::ImageGenerateParams::Style::OrSymbol)) }
      attr_accessor :style

      # A unique identifier representing your end-user, which can help OpenAI to monitor
      # and detect abuse.
      # [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).
      sig { returns(T.nilable(String)) }
      attr_reader :user

      sig { params(user: String).void }
      attr_writer :user

      sig do
        params(
          prompt: String,
          background: T.nilable(OpenAI::Models::ImageGenerateParams::Background::OrSymbol),
          model: T.nilable(T.any(String, OpenAI::Models::ImageModel::OrSymbol)),
          moderation: T.nilable(OpenAI::Models::ImageGenerateParams::Moderation::OrSymbol),
          n: T.nilable(Integer),
          output_compression: T.nilable(Integer),
          output_format: T.nilable(OpenAI::Models::ImageGenerateParams::OutputFormat::OrSymbol),
          quality: T.nilable(OpenAI::Models::ImageGenerateParams::Quality::OrSymbol),
          response_format: T.nilable(OpenAI::Models::ImageGenerateParams::ResponseFormat::OrSymbol),
          size: T.nilable(OpenAI::Models::ImageGenerateParams::Size::OrSymbol),
          style: T.nilable(OpenAI::Models::ImageGenerateParams::Style::OrSymbol),
          user: String,
          request_options: T.any(OpenAI::RequestOptions, OpenAI::Internal::AnyHash)
        )
          .returns(T.attached_class)
      end
      def self.new(
        prompt:,
        background: nil,
        model: nil,
        moderation: nil,
        n: nil,
        output_compression: nil,
        output_format: nil,
        quality: nil,
        response_format: nil,
        size: nil,
        style: nil,
        user: nil,
        request_options: {}
      ); end
      sig do
        override
          .returns(
            {
              prompt: String,
              background: T.nilable(OpenAI::Models::ImageGenerateParams::Background::OrSymbol),
              model: T.nilable(T.any(String, OpenAI::Models::ImageModel::OrSymbol)),
              moderation: T.nilable(OpenAI::Models::ImageGenerateParams::Moderation::OrSymbol),
              n: T.nilable(Integer),
              output_compression: T.nilable(Integer),
              output_format: T.nilable(OpenAI::Models::ImageGenerateParams::OutputFormat::OrSymbol),
              quality: T.nilable(OpenAI::Models::ImageGenerateParams::Quality::OrSymbol),
              response_format: T.nilable(OpenAI::Models::ImageGenerateParams::ResponseFormat::OrSymbol),
              size: T.nilable(OpenAI::Models::ImageGenerateParams::Size::OrSymbol),
              style: T.nilable(OpenAI::Models::ImageGenerateParams::Style::OrSymbol),
              user: String,
              request_options: OpenAI::RequestOptions
            }
          )
      end
      def to_hash; end

      # Allows to set transparency for the background of the generated image(s). This
      # parameter is only supported for `gpt-image-1`. Must be one of `transparent`,
      # `opaque` or `auto` (default value). When `auto` is used, the model will
      # automatically determine the best background for the image.
      #
      # If `transparent`, the output format needs to support transparency, so it should
      # be set to either `png` (default value) or `webp`.
      module Background
        extend OpenAI::Internal::Type::Enum

        TaggedSymbol = T.type_alias { T.all(Symbol, OpenAI::Models::ImageGenerateParams::Background) }
        OrSymbol = T.type_alias { T.any(Symbol, String) }

        TRANSPARENT = T.let(:transparent, OpenAI::Models::ImageGenerateParams::Background::TaggedSymbol)
        OPAQUE = T.let(:opaque, OpenAI::Models::ImageGenerateParams::Background::TaggedSymbol)
        AUTO = T.let(:auto, OpenAI::Models::ImageGenerateParams::Background::TaggedSymbol)

        sig { override.returns(T::Array[OpenAI::Models::ImageGenerateParams::Background::TaggedSymbol]) }
        def self.values; end
      end

      # The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or
      # `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to
      # `gpt-image-1` is used.
      module Model
        extend OpenAI::Internal::Type::Union

        sig { override.returns([String, OpenAI::Models::ImageModel::TaggedSymbol]) }
        def self.variants; end
      end

      # Control the content-moderation level for images generated by `gpt-image-1`. Must
      # be either `low` for less restrictive filtering or `auto` (default value).
      module Moderation
        extend OpenAI::Internal::Type::Enum

        TaggedSymbol = T.type_alias { T.all(Symbol, OpenAI::Models::ImageGenerateParams::Moderation) }
        OrSymbol = T.type_alias { T.any(Symbol, String) }

        LOW = T.let(:low, OpenAI::Models::ImageGenerateParams::Moderation::TaggedSymbol)
        AUTO = T.let(:auto, OpenAI::Models::ImageGenerateParams::Moderation::TaggedSymbol)

        sig { override.returns(T::Array[OpenAI::Models::ImageGenerateParams::Moderation::TaggedSymbol]) }
        def self.values; end
      end

      # The format in which the generated images are returned. This parameter is only
      # supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.
      module OutputFormat
        extend OpenAI::Internal::Type::Enum

        TaggedSymbol = T.type_alias { T.all(Symbol, OpenAI::Models::ImageGenerateParams::OutputFormat) }
        OrSymbol = T.type_alias { T.any(Symbol, String) }

        PNG = T.let(:png, OpenAI::Models::ImageGenerateParams::OutputFormat::TaggedSymbol)
        JPEG = T.let(:jpeg, OpenAI::Models::ImageGenerateParams::OutputFormat::TaggedSymbol)
        WEBP = T.let(:webp, OpenAI::Models::ImageGenerateParams::OutputFormat::TaggedSymbol)

        sig { override.returns(T::Array[OpenAI::Models::ImageGenerateParams::OutputFormat::TaggedSymbol]) }
        def self.values; end
      end

      # The quality of the image that will be generated.
      #
      # - `auto` (default value) will automatically select the best quality for the
      #   given model.
      # - `high`, `medium` and `low` are supported for `gpt-image-1`.
      # - `hd` and `standard` are supported for `dall-e-3`.
      # - `standard` is the only option for `dall-e-2`.
      module Quality
        extend OpenAI::Internal::Type::Enum

        TaggedSymbol = T.type_alias { T.all(Symbol, OpenAI::Models::ImageGenerateParams::Quality) }
        OrSymbol = T.type_alias { T.any(Symbol, String) }

        STANDARD = T.let(:standard, OpenAI::Models::ImageGenerateParams::Quality::TaggedSymbol)
        HD = T.let(:hd, OpenAI::Models::ImageGenerateParams::Quality::TaggedSymbol)
        LOW = T.let(:low, OpenAI::Models::ImageGenerateParams::Quality::TaggedSymbol)
        MEDIUM = T.let(:medium, OpenAI::Models::ImageGenerateParams::Quality::TaggedSymbol)
        HIGH = T.let(:high, OpenAI::Models::ImageGenerateParams::Quality::TaggedSymbol)
        AUTO = T.let(:auto, OpenAI::Models::ImageGenerateParams::Quality::TaggedSymbol)

        sig { override.returns(T::Array[OpenAI::Models::ImageGenerateParams::Quality::TaggedSymbol]) }
        def self.values; end
      end

      # The format in which generated images with `dall-e-2` and `dall-e-3` are
      # returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes
      # after the image has been generated. This parameter isn't supported for
      # `gpt-image-1` which will always return base64-encoded images.
      module ResponseFormat
        extend OpenAI::Internal::Type::Enum

        TaggedSymbol = T.type_alias { T.all(Symbol, OpenAI::Models::ImageGenerateParams::ResponseFormat) }
        OrSymbol = T.type_alias { T.any(Symbol, String) }

        URL = T.let(:url, OpenAI::Models::ImageGenerateParams::ResponseFormat::TaggedSymbol)
        B64_JSON = T.let(:b64_json, OpenAI::Models::ImageGenerateParams::ResponseFormat::TaggedSymbol)

        sig { override.returns(T::Array[OpenAI::Models::ImageGenerateParams::ResponseFormat::TaggedSymbol]) }
        def self.values; end
      end

      # The size of the generated images. Must be one of `1024x1024`, `1536x1024`
      # (landscape), `1024x1536` (portrait), or `auto` (default value) for
      # `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and
      # one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.
      module Size
        extend OpenAI::Internal::Type::Enum

        TaggedSymbol = T.type_alias { T.all(Symbol, OpenAI::Models::ImageGenerateParams::Size) }
        OrSymbol = T.type_alias { T.any(Symbol, String) }

        AUTO = T.let(:auto, OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)
        SIZE_1024X1024 = T.let(:"1024x1024", OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)
        SIZE_1536X1024 = T.let(:"1536x1024", OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)
        SIZE_1024X1536 = T.let(:"1024x1536", OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)
        SIZE_256X256 = T.let(:"256x256", OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)
        SIZE_512X512 = T.let(:"512x512", OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)
        SIZE_1792X1024 = T.let(:"1792x1024", OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)
        SIZE_1024X1792 = T.let(:"1024x1792", OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol)

        sig { override.returns(T::Array[OpenAI::Models::ImageGenerateParams::Size::TaggedSymbol]) }
        def self.values; end
      end

      # The style of the generated images. This parameter is only supported for
      # `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean
      # towards generating hyper-real and dramatic images. Natural causes the model to
      # produce more natural, less hyper-real looking images.
      module Style
        extend OpenAI::Internal::Type::Enum

        TaggedSymbol = T.type_alias { T.all(Symbol, OpenAI::Models::ImageGenerateParams::Style) }
        OrSymbol = T.type_alias { T.any(Symbol, String) }

        VIVID = T.let(:vivid, OpenAI::Models::ImageGenerateParams::Style::TaggedSymbol)
        NATURAL = T.let(:natural, OpenAI::Models::ImageGenerateParams::Style::TaggedSymbol)

        sig { override.returns(T::Array[OpenAI::Models::ImageGenerateParams::Style::TaggedSymbol]) }
        def self.values; end
      end
    end
  end
end
